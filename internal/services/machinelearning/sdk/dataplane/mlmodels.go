package machinelearningservices

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
	"context"
	"github.com/Azure/go-autorest/autorest"
	"github.com/Azure/go-autorest/autorest/azure"
	"github.com/Azure/go-autorest/autorest/validation"
	"github.com/Azure/go-autorest/tracing"
	"github.com/gofrs/uuid"
	"net/http"
)

// MLModelsClient is the these APIs allow end users to manage Azure Machine Learning Services.
type MLModelsClient struct {
	BaseClient
}

// NewMLModelsClient creates an instance of the MLModelsClient client.
func NewMLModelsClient() MLModelsClient {
	return NewMLModelsClientWithBaseURI(DefaultBaseURI)
}

// NewMLModelsClientWithBaseURI creates an instance of the MLModelsClient client using a custom endpoint.  Use this
// when interacting with an Azure cloud that uses a non-standard base URI (sovereign clouds, Azure stack).
func NewMLModelsClientWithBaseURI(baseURI string) MLModelsClient {
	return MLModelsClient{NewWithBaseURI(baseURI)}
}

// Delete deletes a model if it exists.
// Parameters:
// subscriptionID - the Azure Subscription ID.
// resourceGroup - the Name of the resource group in which the workspace is located.
// workspace - the name of the workspace.
// ID - the model id.
func (client MLModelsClient) Delete(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string) (result autorest.Response, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.Delete")
		defer func() {
			sc := -1
			if result.Response != nil {
				sc = result.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	req, err := client.DeletePreparer(ctx, subscriptionID, resourceGroup, workspace, ID)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Delete", nil, "Failure preparing request")
		return
	}

	resp, err := client.DeleteSender(req)
	if err != nil {
		result.Response = resp
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Delete", resp, "Failure sending request")
		return
	}

	result, err = client.DeleteResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Delete", resp, "Failure responding to request")
		return
	}

	return
}

// DeletePreparer prepares the Delete request.
func (client MLModelsClient) DeletePreparer(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string) (*http.Request, error) {
	pathParameters := map[string]interface{}{
		"id":             autorest.Encode("path", ID),
		"resourceGroup":  autorest.Encode("path", resourceGroup),
		"subscriptionId": autorest.Encode("path", subscriptionID),
		"workspace":      autorest.Encode("path", workspace),
	}

	preparer := autorest.CreatePreparer(
		autorest.AsDelete(),
		autorest.WithBaseURL(client.BaseURI),
		autorest.WithPathParameters("/modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models/{id}", pathParameters))
	return preparer.Prepare((&http.Request{}).WithContext(ctx))
}

// DeleteSender sends the Delete request. The method will close the
// http.Response Body if it receives an error.
func (client MLModelsClient) DeleteSender(req *http.Request) (*http.Response, error) {
	return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
}

// DeleteResponder handles the response to the Delete request. The method always
// closes the http.Response Body.
func (client MLModelsClient) DeleteResponder(resp *http.Response) (result autorest.Response, err error) {
	err = autorest.Respond(
		resp,
		azure.WithErrorUnlessStatusCode(http.StatusOK, http.StatusNoContent),
		autorest.ByClosing())
	result.Response = resp
	return
}

// GetMetrics the operational events collected for the Model are returned.
// Parameters:
// subscriptionID - the Azure Subscription ID.
// resourceGroup - the Name of the resource group in which the workspace is located.
// workspace - the name of the workspace.
// ID - the Model Id.
// startDate - the start date from which to retrieve metrics, ISO 8601 literal format.
// endDate - the end date from which to retrieve metrics, ISO 8601 literal format.
func (client MLModelsClient) GetMetrics(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string, startDate string, endDate string) (result ModelOperationalState, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.GetMetrics")
		defer func() {
			sc := -1
			if result.Response.Response != nil {
				sc = result.Response.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	req, err := client.GetMetricsPreparer(ctx, subscriptionID, resourceGroup, workspace, ID, startDate, endDate)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "GetMetrics", nil, "Failure preparing request")
		return
	}

	resp, err := client.GetMetricsSender(req)
	if err != nil {
		result.Response = autorest.Response{Response: resp}
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "GetMetrics", resp, "Failure sending request")
		return
	}

	result, err = client.GetMetricsResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "GetMetrics", resp, "Failure responding to request")
		return
	}

	return
}

// GetMetricsPreparer prepares the GetMetrics request.
func (client MLModelsClient) GetMetricsPreparer(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string, startDate string, endDate string) (*http.Request, error) {
	pathParameters := map[string]interface{}{
		"id":             autorest.Encode("path", ID),
		"resourceGroup":  autorest.Encode("path", resourceGroup),
		"subscriptionId": autorest.Encode("path", subscriptionID),
		"workspace":      autorest.Encode("path", workspace),
	}

	queryParameters := map[string]interface{}{}
	if len(startDate) > 0 {
		queryParameters["startDate"] = autorest.Encode("query", startDate)
	}
	if len(endDate) > 0 {
		queryParameters["endDate"] = autorest.Encode("query", endDate)
	}

	preparer := autorest.CreatePreparer(
		autorest.AsGet(),
		autorest.WithBaseURL(client.BaseURI),
		autorest.WithPathParameters("/modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models/{id}/metrics", pathParameters),
		autorest.WithQueryParameters(queryParameters))
	return preparer.Prepare((&http.Request{}).WithContext(ctx))
}

// GetMetricsSender sends the GetMetrics request. The method will close the
// http.Response Body if it receives an error.
func (client MLModelsClient) GetMetricsSender(req *http.Request) (*http.Response, error) {
	return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
}

// GetMetricsResponder handles the response to the GetMetrics request. The method always
// closes the http.Response Body.
func (client MLModelsClient) GetMetricsResponder(resp *http.Response) (result ModelOperationalState, err error) {
	err = autorest.Respond(
		resp,
		azure.WithErrorUnlessStatusCode(http.StatusOK),
		autorest.ByUnmarshallingJSON(&result),
		autorest.ByClosing())
	result.Response = autorest.Response{Response: resp}
	return
}

// ListQuery the result list can be filtered using tag and name. If no filter is passed, the query lists all the Models
// in the given workspace. The returned list is paginated and the count of items in each page is an optional parameter.
// Parameters:
// subscriptionID - the Azure Subscription ID.
// resourceGroup - the Name of the resource group in which the workspace is located.
// workspace - the name of the workspace.
// name - the object name.
// framework - the framework.
// description - the object description.
// count - the number of items to retrieve in a page.
// skipToken - the continuation token to retrieve the next page.
// tags - a set of tags with which to filter the returned models.
// It is a comma separated string of tags key or tags key=value
// Example: tagKey1,tagKey2,tagKey3=value3
// properties - a set of properties with which to filter the returned models.
// It is a comma separated string of properties key and/or properties key=value
// Example: propKey1,propKey2,propKey3=value3
// runID - the runId which created the model.
// orderBy - an option to specify how the models are ordered in the response.
func (client MLModelsClient) ListQuery(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, name string, framework string, description string, count *int32, skipToken string, tags string, properties string, runID string, orderBy string) (result PaginatedModelListPage, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.ListQuery")
		defer func() {
			sc := -1
			if result.pml.Response.Response != nil {
				sc = result.pml.Response.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	result.fn = client.listQueryNextResults
	req, err := client.ListQueryPreparer(ctx, subscriptionID, resourceGroup, workspace, name, framework, description, count, skipToken, tags, properties, runID, orderBy)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "ListQuery", nil, "Failure preparing request")
		return
	}

	resp, err := client.ListQuerySender(req)
	if err != nil {
		result.pml.Response = autorest.Response{Response: resp}
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "ListQuery", resp, "Failure sending request")
		return
	}

	result.pml, err = client.ListQueryResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "ListQuery", resp, "Failure responding to request")
		return
	}
	if result.pml.hasNextLink() && result.pml.IsEmpty() {
		err = result.NextWithContext(ctx)
		return
	}

	return
}

// ListQueryPreparer prepares the ListQuery request.
func (client MLModelsClient) ListQueryPreparer(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, name string, framework string, description string, count *int32, skipToken string, tags string, properties string, runID string, orderBy string) (*http.Request, error) {
	pathParameters := map[string]interface{}{
		"resourceGroup":  autorest.Encode("path", resourceGroup),
		"subscriptionId": autorest.Encode("path", subscriptionID),
		"workspace":      autorest.Encode("path", workspace),
	}

	queryParameters := map[string]interface{}{}
	if len(name) > 0 {
		queryParameters["name"] = autorest.Encode("query", name)
	}
	if len(framework) > 0 {
		queryParameters["framework"] = autorest.Encode("query", framework)
	}
	if len(description) > 0 {
		queryParameters["description"] = autorest.Encode("query", description)
	}
	if count != nil {
		queryParameters["count"] = autorest.Encode("query", *count)
	}
	if len(skipToken) > 0 {
		queryParameters["$skipToken"] = autorest.Encode("query", skipToken)
	}
	if len(tags) > 0 {
		queryParameters["tags"] = autorest.Encode("query", tags)
	}
	if len(properties) > 0 {
		queryParameters["properties"] = autorest.Encode("query", properties)
	}
	if len(runID) > 0 {
		queryParameters["runId"] = autorest.Encode("query", runID)
	}
	if len(string(orderBy)) > 0 {
		queryParameters["orderBy"] = autorest.Encode("query", orderBy)
	} else {
		queryParameters["orderBy"] = autorest.Encode("query", "CreatedAtDesc")
	}

	preparer := autorest.CreatePreparer(
		autorest.AsGet(),
		autorest.WithBaseURL(client.BaseURI),
		autorest.WithPathParameters("/modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models", pathParameters),
		autorest.WithQueryParameters(queryParameters))
	return preparer.Prepare((&http.Request{}).WithContext(ctx))
}

// ListQuerySender sends the ListQuery request. The method will close the
// http.Response Body if it receives an error.
func (client MLModelsClient) ListQuerySender(req *http.Request) (*http.Response, error) {
	return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
}

// ListQueryResponder handles the response to the ListQuery request. The method always
// closes the http.Response Body.
func (client MLModelsClient) ListQueryResponder(resp *http.Response) (result PaginatedModelList, err error) {
	err = autorest.Respond(
		resp,
		azure.WithErrorUnlessStatusCode(http.StatusOK),
		autorest.ByUnmarshallingJSON(&result),
		autorest.ByClosing())
	result.Response = autorest.Response{Response: resp}
	return
}

// listQueryNextResults retrieves the next set of results, if any.
func (client MLModelsClient) listQueryNextResults(ctx context.Context, lastResults PaginatedModelList) (result PaginatedModelList, err error) {
	req, err := lastResults.paginatedModelListPreparer(ctx)
	if err != nil {
		return result, autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "listQueryNextResults", nil, "Failure preparing next results request")
	}
	if req == nil {
		return
	}
	resp, err := client.ListQuerySender(req)
	if err != nil {
		result.Response = autorest.Response{Response: resp}
		return result, autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "listQueryNextResults", resp, "Failure sending next results request")
	}
	result, err = client.ListQueryResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "listQueryNextResults", resp, "Failure responding to next results request")
	}
	return
}

// ListQueryComplete enumerates all values, automatically crossing page boundaries as required.
func (client MLModelsClient) ListQueryComplete(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, name string, framework string, description string, count *int32, skipToken string, tags string, properties string, runID string, orderBy string) (result PaginatedModelListIterator, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.ListQuery")
		defer func() {
			sc := -1
			if result.Response().Response.Response != nil {
				sc = result.page.Response().Response.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	result.page, err = client.ListQuery(ctx, subscriptionID, resourceGroup, workspace, name, framework, description, count, skipToken, tags, properties, runID, orderBy)
	return
}

// Patch updates an existing model with the specified patch.
// Parameters:
// subscriptionID - the Azure Subscription ID.
// resourceGroup - the Name of the resource group in which the workspace is located.
// workspace - the name of the workspace.
// ID - the model id.
// patch - the payload that is used to patch the model.
func (client MLModelsClient) Patch(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string, patch []JSONPatchOperation) (result Model, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.Patch")
		defer func() {
			sc := -1
			if result.Response.Response != nil {
				sc = result.Response.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	if err := validation.Validate([]validation.Validation{
		{TargetValue: patch,
			Constraints: []validation.Constraint{{Target: "patch", Name: validation.Null, Rule: true, Chain: nil}}}}); err != nil {
		return result, validation.NewError("machinelearningservices.MLModelsClient", "Patch", err.Error())
	}

	req, err := client.PatchPreparer(ctx, subscriptionID, resourceGroup, workspace, ID, patch)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Patch", nil, "Failure preparing request")
		return
	}

	resp, err := client.PatchSender(req)
	if err != nil {
		result.Response = autorest.Response{Response: resp}
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Patch", resp, "Failure sending request")
		return
	}

	result, err = client.PatchResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Patch", resp, "Failure responding to request")
		return
	}

	return
}

// PatchPreparer prepares the Patch request.
func (client MLModelsClient) PatchPreparer(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string, patch []JSONPatchOperation) (*http.Request, error) {
	pathParameters := map[string]interface{}{
		"id":             autorest.Encode("path", ID),
		"resourceGroup":  autorest.Encode("path", resourceGroup),
		"subscriptionId": autorest.Encode("path", subscriptionID),
		"workspace":      autorest.Encode("path", workspace),
	}

	preparer := autorest.CreatePreparer(
		autorest.AsContentType("application/json-patch+json; charset=utf-8"),
		autorest.AsPatch(),
		autorest.WithBaseURL(client.BaseURI),
		autorest.WithPathParameters("/modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models/{id}", pathParameters),
		autorest.WithJSON(patch))
	return preparer.Prepare((&http.Request{}).WithContext(ctx))
}

// PatchSender sends the Patch request. The method will close the
// http.Response Body if it receives an error.
func (client MLModelsClient) PatchSender(req *http.Request) (*http.Response, error) {
	return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
}

// PatchResponder handles the response to the Patch request. The method always
// closes the http.Response Body.
func (client MLModelsClient) PatchResponder(resp *http.Response) (result Model, err error) {
	err = autorest.Respond(
		resp,
		azure.WithErrorUnlessStatusCode(http.StatusOK),
		autorest.ByUnmarshallingJSON(&result),
		autorest.ByClosing())
	result.Response = autorest.Response{Response: resp}
	return
}

// QueryByID gets a model by model id.
// Parameters:
// subscriptionID - the Azure Subscription ID.
// resourceGroup - the Name of the resource group in which the workspace is located.
// workspace - the name of the workspace.
// ID - the model id.
func (client MLModelsClient) QueryByID(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string) (result Model, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.QueryByID")
		defer func() {
			sc := -1
			if result.Response.Response != nil {
				sc = result.Response.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	req, err := client.QueryByIDPreparer(ctx, subscriptionID, resourceGroup, workspace, ID)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "QueryByID", nil, "Failure preparing request")
		return
	}

	resp, err := client.QueryByIDSender(req)
	if err != nil {
		result.Response = autorest.Response{Response: resp}
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "QueryByID", resp, "Failure sending request")
		return
	}

	result, err = client.QueryByIDResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "QueryByID", resp, "Failure responding to request")
		return
	}

	return
}

// QueryByIDPreparer prepares the QueryByID request.
func (client MLModelsClient) QueryByIDPreparer(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, ID string) (*http.Request, error) {
	pathParameters := map[string]interface{}{
		"id":             autorest.Encode("path", ID),
		"resourceGroup":  autorest.Encode("path", resourceGroup),
		"subscriptionId": autorest.Encode("path", subscriptionID),
		"workspace":      autorest.Encode("path", workspace),
	}

	preparer := autorest.CreatePreparer(
		autorest.AsGet(),
		autorest.WithBaseURL(client.BaseURI),
		autorest.WithPathParameters("/modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models/{id}", pathParameters))
	return preparer.Prepare((&http.Request{}).WithContext(ctx))
}

// QueryByIDSender sends the QueryByID request. The method will close the
// http.Response Body if it receives an error.
func (client MLModelsClient) QueryByIDSender(req *http.Request) (*http.Response, error) {
	return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
}

// QueryByIDResponder handles the response to the QueryByID request. The method always
// closes the http.Response Body.
func (client MLModelsClient) QueryByIDResponder(resp *http.Response) (result Model, err error) {
	err = autorest.Respond(
		resp,
		azure.WithErrorUnlessStatusCode(http.StatusOK),
		autorest.ByUnmarshallingJSON(&result),
		autorest.ByClosing())
	result.Response = autorest.Response{Response: resp}
	return
}

// Register register the model provided.
// Parameters:
// subscriptionID - the Azure Subscription ID.
// resourceGroup - the Name of the resource group in which the workspace is located.
// workspace - the name of the workspace.
// model - the payload that is used to register the model.
func (client MLModelsClient) Register(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, model Model) (result Model, err error) {
	if tracing.IsEnabled() {
		ctx = tracing.StartSpan(ctx, fqdn+"/MLModelsClient.Register")
		defer func() {
			sc := -1
			if result.Response.Response != nil {
				sc = result.Response.Response.StatusCode
			}
			tracing.EndSpan(ctx, sc, err)
		}()
	}
	if err := validation.Validate([]validation.Validation{
		{TargetValue: model,
			Constraints: []validation.Constraint{{Target: "model.Name", Name: validation.Null, Rule: true, Chain: nil},
				{Target: "model.URL", Name: validation.Null, Rule: true, Chain: nil},
				{Target: "model.MimeType", Name: validation.Null, Rule: true, Chain: nil}}}}); err != nil {
		return result, validation.NewError("machinelearningservices.MLModelsClient", "Register", err.Error())
	}

	req, err := client.RegisterPreparer(ctx, subscriptionID, resourceGroup, workspace, model)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Register", nil, "Failure preparing request")
		return
	}

	resp, err := client.RegisterSender(req)
	if err != nil {
		result.Response = autorest.Response{Response: resp}
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Register", resp, "Failure sending request")
		return
	}

	result, err = client.RegisterResponder(resp)
	if err != nil {
		err = autorest.NewErrorWithError(err, "machinelearningservices.MLModelsClient", "Register", resp, "Failure responding to request")
		return
	}

	return
}

// RegisterPreparer prepares the Register request.
func (client MLModelsClient) RegisterPreparer(ctx context.Context, subscriptionID uuid.UUID, resourceGroup string, workspace string, model Model) (*http.Request, error) {
	pathParameters := map[string]interface{}{
		"resourceGroup":  autorest.Encode("path", resourceGroup),
		"subscriptionId": autorest.Encode("path", subscriptionID),
		"workspace":      autorest.Encode("path", workspace),
	}

	model.CreatedTime = nil
	model.ModifiedTime = nil
	preparer := autorest.CreatePreparer(
		autorest.AsContentType("application/json; charset=utf-8"),
		autorest.AsPost(),
		autorest.WithBaseURL(client.BaseURI),
		autorest.WithPathParameters("/modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models", pathParameters),
		autorest.WithJSON(model))
	return preparer.Prepare((&http.Request{}).WithContext(ctx))
}

// RegisterSender sends the Register request. The method will close the
// http.Response Body if it receives an error.
func (client MLModelsClient) RegisterSender(req *http.Request) (*http.Response, error) {
	return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
}

// RegisterResponder handles the response to the Register request. The method always
// closes the http.Response Body.
func (client MLModelsClient) RegisterResponder(resp *http.Response) (result Model, err error) {
	err = autorest.Respond(
		resp,
		azure.WithErrorUnlessStatusCode(http.StatusOK),
		autorest.ByUnmarshallingJSON(&result),
		autorest.ByClosing())
	result.Response = autorest.Response{Response: resp}
	return
}
